# ğŸ§ª EstratÃ©gia de OrganizaÃ§Ã£o de Testes

**Data**: 2026-01-20
**Objetivo**: Definir a melhor forma de organizar, criar e manter testes para atingir 80%+ de cobertura
**Status**: ğŸ“‹ PLANO ESTRATÃ‰GICO

---

## ğŸ“Š SituaÃ§Ã£o Atual

### Estado Atual dos Testes

```
ğŸ“ tests/
â”œâ”€â”€ ğŸ“„ 20 arquivos de teste (.js)
â”œâ”€â”€ ğŸ“„ 2 manuais (.txt)
â”œâ”€â”€ ğŸ“„ 1 helper (helpers.js)
â”œâ”€â”€ ğŸ“ 1 subpasta (integration/)
â””â”€â”€ ğŸ“ˆ 3.735 linhas de cÃ³digo

DistribuiÃ§Ã£o:
- âœ… 14 testes funcionais (pass)
- âš ï¸  5 testes problemÃ¡ticos (precisam refatoraÃ§Ã£o)
- ğŸ“Š Cobertura estimada: 14% (19/135 arquivos)
```

### Problemas Identificados

1. **âŒ Estrutura Plana**: Todos os testes na raiz do diretÃ³rio
2. **âŒ Naming Inconsistente**: Mistura de `test_*`, `*.test.js`, `*_fixes.js`
3. **âŒ Sem SeparaÃ§Ã£o**: Unit/Integration/E2E misturados
4. **âŒ Sem Framework**: Tests customizados com `runTest()`, sem runner padrÃ£o
5. **âŒ Sem Coverage**: NÃ£o hÃ¡ mediÃ§Ã£o de cobertura
6. **âŒ Fixtures Inline**: Dados de teste hardcoded nos arquivos
7. **âŒ DependÃªncias Mistas**: Alguns tests precisam agente rodando, outros nÃ£o

---

## ğŸ¯ VisÃ£o EstratÃ©gica: PirÃ¢mide de Testes

```
                    ğŸ”º
                   /  \
                  / E2E \          â† 10% dos testes (lento, frÃ¡gil)
                 /________\         â€¢ Fluxo completo de tarefa
                /          \        â€¢ Boot sequence end-to-end
               / Integration\      â† 30% dos testes (moderado)
              /______________\      â€¢ Driver + NERV + Kernel
             /                \     â€¢ API + Storage + Queue
            /    Unit Tests    \   â† 60% dos testes (rÃ¡pido, isolado)
           /____________________\   â€¢ FunÃ§Ãµes puras, classes isoladas
                                    â€¢ Mocks para dependÃªncias

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PROPORÃ‡ÃƒO IDEAL:                                            â”‚
â”‚ â€¢ 60% Unit (rÃ¡pido < 100ms, isolado, sem I/O)              â”‚
â”‚ â€¢ 30% Integration (< 1s, cross-component)                  â”‚
â”‚ â€¢ 10% E2E (< 10s, full stack)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ Estrutura de DiretÃ³rios Proposta

### Estrutura Completa

```
tests/
â”‚
â”œâ”€â”€ ğŸ“ unit/                          # 60% - Testes isolados (sem I/O)
â”‚   â”œâ”€â”€ ğŸ“ core/                      # 30 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_config.spec.js      # âœ… JÃ¡ existe (consolidar)
â”‚   â”‚   â”œâ”€â”€ test_logger.spec.js      # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_schemas.spec.js     # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_identity.spec.js    # âœ… JÃ¡ existe
â”‚   â”‚   â”œâ”€â”€ test_forensics.spec.js   # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_context_engine.spec.js
â”‚   â”‚   â””â”€â”€ test_memory.spec.js
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ nerv/                      # 22 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_nerv_core.spec.js   # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_buffers.spec.js     # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_emission.spec.js    # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_reception.spec.js   # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_correlation.spec.js # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_transport.spec.js   # ğŸŸ  MÃ‰DIO
â”‚   â”‚   â””â”€â”€ test_telemetry.spec.js   # ğŸŸ  MÃ‰DIO
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ kernel/                    # 13 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_execution_engine.spec.js    # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_task_runtime.spec.js        # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_policy_engine.spec.js       # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_observation_store.spec.js   # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_kernel_loop.spec.js         # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_nerv_bridge.spec.js         # ğŸŸ  MÃ‰DIO
â”‚   â”‚   â””â”€â”€ test_kernel_state.spec.js        # ğŸŸ  MÃ‰DIO
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ driver/                    # 17 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_factory.spec.js              # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_lifecycle_manager.spec.js    # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_base_driver.spec.js          # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_target_driver.spec.js        # ğŸŸ¡ ALTO
â”‚   â”‚   â””â”€â”€ test_driver_modules.spec.js       # ğŸŸ¡ ALTO
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ infra/                     # 22 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_io.spec.js          # ğŸ”´ CRÃTICO (P5.2 bug)
â”‚   â”‚   â”œâ”€â”€ test_lock_manager.spec.js         # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_queue.spec.js                # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_storage.spec.js              # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_fs_operations.spec.js        # ğŸŸ¡ ALTO
â”‚   â”‚   â””â”€â”€ test_browser_pool.spec.js         # âœ… JÃ¡ existe
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ server/                    # 20 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_server_main.spec.js
â”‚   â”‚   â”œâ”€â”€ test_api_routes.spec.js  # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_middleware.spec.js  # ğŸŸ  MÃ‰DIO
â”‚   â”‚   â”œâ”€â”€ test_realtime.spec.js    # ğŸŸ¡ ALTO
â”‚   â”‚   â””â”€â”€ test_watchers.spec.js    # ğŸŸ¢ BAIXO
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ state/                     # 11 arquivos fonte
â”‚   â”‚   â”œâ”€â”€ test_state_kernel.spec.js
â”‚   â”‚   â”œâ”€â”€ test_state_memory.spec.js
â”‚   â”‚   â””â”€â”€ test_state_tasks.spec.js # ğŸŸ¡ ALTO
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ logic/                     # 5 arquivos fonte
â”‚       â””â”€â”€ test_validation.spec.js   # ğŸŸ¡ ALTO
â”‚
â”œâ”€â”€ ğŸ“ integration/                   # 30% - Cross-component
â”‚   â”œâ”€â”€ ğŸ“ kernel/
â”‚   â”‚   â”œâ”€â”€ test_kernel_driver_flow.spec.js
â”‚   â”‚   â””â”€â”€ test_kernel_nerv_integration.spec.js
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ driver/
â”‚   â”‚   â”œâ”€â”€ test_chatgpt_driver.spec.js      # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_gemini_driver.spec.js       # ğŸŸ¡ ALTO
â”‚   â”‚   â”œâ”€â”€ test_driver_nerv.spec.js         # âœ… JÃ¡ existe
â”‚   â”‚   â””â”€â”€ test_driver_telemetry.spec.js
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ api/
â”‚   â”‚   â”œâ”€â”€ test_api_crud.spec.js            # ğŸ”´ CRÃTICO
â”‚   â”‚   â”œâ”€â”€ test_health_endpoint.spec.js     # âœ… JÃ¡ existe
â”‚   â”‚   â””â”€â”€ test_realtime_events.spec.js     # ğŸŸ¡ ALTO
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ queue/
â”‚   â”‚   â”œâ”€â”€ test_queue_flow.spec.js          # ğŸ”´ CRÃTICO
â”‚   â”‚   â””â”€â”€ test_task_persistence.spec.js
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ browser/
â”‚       â”œâ”€â”€ test_connection_orchestrator.spec.js  # âœ… JÃ¡ existe
â”‚       â””â”€â”€ test_browser_lifecycle.spec.js
â”‚
â”œâ”€â”€ ğŸ“ e2e/                           # 10% - Full stack
â”‚   â”œâ”€â”€ test_boot_sequence.spec.js   # âœ… JÃ¡ existe
â”‚   â”œâ”€â”€ test_ariadne_thread.spec.js  # âœ… JÃ¡ existe (E2E completo)
â”‚   â”œâ”€â”€ test_task_full_flow.spec.js  # ğŸ”´ Tarefa completa (criar â†’ executar â†’ resposta)
â”‚   â””â”€â”€ test_graceful_shutdown.spec.js
â”‚
â”œâ”€â”€ ğŸ“ regression/                    # Testes de regressÃ£o (P1-P5)
â”‚   â”œâ”€â”€ test_p1_fixes.spec.js        # âœ… JÃ¡ existe
â”‚   â”œâ”€â”€ test_p2_fixes.spec.js        # âœ… JÃ¡ existe
â”‚   â”œâ”€â”€ test_p3_fixes.spec.js        # âœ… JÃ¡ existe
â”‚   â”œâ”€â”€ test_p4_fixes.spec.js        # âœ… JÃ¡ existe
â”‚   â””â”€â”€ test_p5_fixes.spec.js        # âš ï¸  P5.2 precisa fix
â”‚
â”œâ”€â”€ ğŸ“ fixtures/                      # Dados de teste reutilizÃ¡veis
â”‚   â”œâ”€â”€ ğŸ“ tasks/                     # Tasks mockadas
â”‚   â”‚   â”œâ”€â”€ task_simple.json
â”‚   â”‚   â”œâ”€â”€ task_complex.json
â”‚   â”‚   â”œâ”€â”€ task_invalid.json
â”‚   â”‚   â””â”€â”€ task_chatgpt.json
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ responses/                 # Responses mockadas
â”‚   â”‚   â”œâ”€â”€ response_success.json
â”‚   â”‚   â”œâ”€â”€ response_error.json
â”‚   â”‚   â””â”€â”€ response_timeout.json
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ config/                    # Configs de teste
â”‚   â”‚   â”œâ”€â”€ config_minimal.json
â”‚   â”‚   â”œâ”€â”€ config_full.json
â”‚   â”‚   â””â”€â”€ dynamic_rules_test.json
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“ dna/                       # DNA samples
â”‚       â”œâ”€â”€ dna_v1.json
â”‚       â””â”€â”€ dna_v2.json
â”‚
â”œâ”€â”€ ğŸ“ mocks/                         # Mocks reutilizÃ¡veis
â”‚   â”œâ”€â”€ mock_browser.js               # Mock Puppeteer browser
â”‚   â”œâ”€â”€ mock_nerv.js                  # Mock NERV event bus
â”‚   â”œâ”€â”€ mock_driver.js                # Mock driver base
â”‚   â”œâ”€â”€ mock_page.js                  # Mock Puppeteer page
â”‚   â””â”€â”€ mock_logger.js                # Mock logger (silent)
â”‚
â”œâ”€â”€ ğŸ“ helpers/                       # UtilitÃ¡rios de teste
â”‚   â”œâ”€â”€ test_helpers.js               # âœ… JÃ¡ existe (renomear)
â”‚   â”œâ”€â”€ assertion_helpers.js          # Assertions customizadas
â”‚   â”œâ”€â”€ async_helpers.js              # waitForCondition, retry, etc.
â”‚   â”œâ”€â”€ mock_factory.js               # Factory para criar mocks
â”‚   â””â”€â”€ cleanup_helpers.js            # Limpar estado entre testes
â”‚
â”œâ”€â”€ ğŸ“ manual/                        # Testes manuais (documentaÃ§Ã£o)
â”‚   â”œâ”€â”€ test_multi_tab.md             # âœ… JÃ¡ existe (.txt â†’ .md)
â”‚   â”œâ”€â”€ test_stall_simulation.md      # âœ… JÃ¡ existe (.txt â†’ .md)
â”‚   â””â”€â”€ test_chrome_external.md       # ConexÃ£o com Chrome externo
â”‚
â”œâ”€â”€ ğŸ“ performance/                   # Testes de performance (futuro)
â”‚   â”œâ”€â”€ benchmark_queue.spec.js
â”‚   â”œâ”€â”€ benchmark_driver.spec.js
â”‚   â””â”€â”€ load_test.spec.js
â”‚
â”œâ”€â”€ ğŸ“„ setup.js                       # Setup global (antes de todos os testes)
â”œâ”€â”€ ğŸ“„ teardown.js                    # Teardown global (depois de todos os testes)
â”œâ”€â”€ ğŸ“„ jest.config.js                 # ConfiguraÃ§Ã£o Jest
â””â”€â”€ ğŸ“„ README.md                      # DocumentaÃ§Ã£o de testes

Total estimado:
- 49 unit test suites
- 15 integration test suites
- 4 e2e test suites
- 5 regression test suites
= 73 test suites
```

---

## ğŸ”§ Escolha de Framework de Testes

### OpÃ§Ãµes Avaliadas

| Framework | Vantagens | Desvantagens | RecomendaÃ§Ã£o |
|-----------|-----------|--------------|--------------|
| **Node.js `node:test`** | âœ… Nativo (Node 20+)<br>âœ… Zero deps<br>âœ… RÃ¡pido | âŒ Menos features<br>âŒ Ecosystem menor | â­â­â­ **RECOMENDADO** |
| **Jest** | âœ… Maduro<br>âœ… Ecosystem rico<br>âœ… Mocking built-in | âŒ Pesado (19MB)<br>âŒ Lento em grandes bases | â­â­â­â­ Alternativa |
| **Vitest** | âœ… Muito rÃ¡pido<br>âœ… ESM nativo<br>âœ… Compatible Jest | âŒ Mais novo<br>âŒ Foco em Vite | â­â­ NÃ£o ideal |
| **Mocha + Chai** | âœ… FlexÃ­vel<br>âœ… Escolha de assertion libs | âŒ Precisa configuraÃ§Ã£o<br>âŒ Sem mocking built-in | â­ Legacy |

### âœ… DecisÃ£o: Node.js `node:test` + c8 coverage

**Justificativa**:

```javascript
// âœ… VANTAGENS:
// 1. Nativo no Node.js 20+ (zero dependÃªncias extras)
// 2. Syntax similar ao Jest (describe, it, beforeEach)
// 3. Suporte a async/await, hooks, mocking
// 4. Integra com c8 para coverage
// 5. Futureproof (mantido pelo Node.js core)

// âŒ DESVANTAGEM:
// - Ecosystem menor que Jest
// - Alguns features avanÃ§ados faltando

// ğŸ¯ CONCLUSÃƒO: Perfeito para nosso caso (codebase Node.js puro)
```

---

## ğŸ“ ConvenÃ§Ãµes de Naming

### PadrÃ£o de Nomenclatura

```javascript
// âœ… PADRÃƒO ADOTADO:
tests/
  unit/
    core/
      test_config.spec.js           â† Unit test
      test_logger.spec.js
  integration/
    api/
      test_api_routes.spec.js       â† Integration test
  e2e/
    test_boot_sequence.spec.js      â† E2E test
  regression/
    test_p1_fixes.spec.js           â† Regression test

// ğŸ“‹ REGRAS:
// 1. Prefixo: "test_" para todos os testes
// 2. Nome: snake_case do mÃ³dulo testado
// 3. Sufixo: ".spec.js" para testes
// 4. Fixtures: sem prefixo "test_", sÃ³ o nome
// 5. Mocks: "mock_" + nome
// 6. Helpers: nome descritivo + "_helpers.js"
```

### Nomenclatura Dentro do Arquivo

```javascript
// âœ… BOM:
describe('ExecutionEngine', () => {
    describe('executeTask()', () => {
        it('should execute task successfully when all deps are valid', async () => {
            // ...
        });

        it('should throw error when taskRuntime is missing', async () => {
            // ...
        });

        it('should emit telemetry event on completion', async () => {
            // ...
        });
    });

    describe('evaluateState()', () => {
        it('should return correct decision proposals', async () => {
            // ...
        });
    });
});

// âŒ RUIM:
describe('Test 1', () => {
    it('works', () => {
        // NÃ£o descritivo
    });
});
```

---

## ğŸ¨ Template de Teste PadrÃ£o

### Unit Test Template

```javascript
/**
 * Unit Test: [Module Name]
 *
 * Tests: [src/path/to/module.js]
 * Coverage: [Funcionalidades testadas]
 *
 * @group unit
 * @group [categoria] (core, kernel, driver, etc)
 */

const { describe, it, beforeEach, afterEach, mock } = require('node:test');
const assert = require('node:assert');

// System Under Test (SUT)
const ModuleName = require('../../../src/path/to/module');

// Mocks
const mockLogger = require('../../mocks/mock_logger');
const mockNerv = require('../../mocks/mock_nerv');

describe('ModuleName', () => {
    let instance;
    let mockDeps;

    beforeEach(() => {
        // Setup: criar instÃ¢ncia com mocks
        mockDeps = {
            logger: mockLogger.create(),
            nerv: mockNerv.create()
        };

        instance = new ModuleName(mockDeps);
    });

    afterEach(() => {
        // Cleanup: resetar mocks, fechar conexÃµes, etc
        mockLogger.reset();
        mockNerv.reset();
    });

    // ===== CONSTRUCTOR =====
    describe('constructor()', () => {
        it('should initialize with valid dependencies', () => {
            assert.ok(instance);
            assert.strictEqual(typeof instance.method, 'function');
        });

        it('should throw when required dependency is missing', () => {
            assert.throws(
                () => new ModuleName({ /* logger missing */ }),
                { message: /logger/i }
            );
        });

        it('should use default values for optional parameters', () => {
            const defaultInstance = new ModuleName(mockDeps);
            assert.strictEqual(defaultInstance.timeout, 5000); // default
        });
    });

    // ===== HAPPY PATH =====
    describe('mainMethod()', () => {
        it('should return expected result for valid input', async () => {
            const input = { foo: 'bar' };
            const result = await instance.mainMethod(input);

            assert.strictEqual(result.status, 'success');
            assert.deepStrictEqual(result.data, { processed: true });
        });

        it('should emit telemetry event on success', async () => {
            await instance.mainMethod({ foo: 'bar' });

            assert.strictEqual(mockNerv.emittedEvents.length, 1);
            assert.strictEqual(mockNerv.emittedEvents[0].type, 'MODULE_SUCCESS');
        });
    });

    // ===== ERROR HANDLING =====
    describe('mainMethod() - error cases', () => {
        it('should handle invalid input gracefully', async () => {
            await assert.rejects(
                () => instance.mainMethod(null),
                { message: /invalid input/i }
            );
        });

        it('should retry on transient errors', async () => {
            let attempts = 0;
            mockDeps.externalService = mock.fn(() => {
                attempts++;
                if (attempts < 3) throw new Error('Transient');
                return 'success';
            });

            const result = await instance.mainMethod({ retry: true });

            assert.strictEqual(attempts, 3);
            assert.strictEqual(result, 'success');
        });

        it('should emit error telemetry on failure', async () => {
            await assert.rejects(() => instance.mainMethod(null));

            const errorEvent = mockNerv.emittedEvents.find(e => e.type === 'MODULE_ERROR');
            assert.ok(errorEvent);
            assert.match(errorEvent.error, /invalid input/i);
        });
    });

    // ===== EDGE CASES =====
    describe('mainMethod() - edge cases', () => {
        it('should handle empty input', async () => {
            const result = await instance.mainMethod({});
            assert.strictEqual(result.status, 'empty');
        });

        it('should handle very large input (performance)', async () => {
            const largeInput = { data: 'x'.repeat(1000000) }; // 1MB
            const start = Date.now();

            await instance.mainMethod(largeInput);

            const elapsed = Date.now() - start;
            assert.ok(elapsed < 1000, 'Should process 1MB in < 1s');
        });

        it('should be idempotent (multiple calls same result)', async () => {
            const input = { foo: 'bar' };

            const result1 = await instance.mainMethod(input);
            const result2 = await instance.mainMethod(input);

            assert.deepStrictEqual(result1, result2);
        });
    });

    // ===== INTEGRATION WITH DEPENDENCIES =====
    describe('integration with logger', () => {
        it('should log info messages', async () => {
            await instance.mainMethod({ foo: 'bar' });

            assert.ok(mockLogger.calls.some(c => c.level === 'INFO'));
        });

        it('should log errors with context', async () => {
            await assert.rejects(() => instance.mainMethod(null));

            const errorLog = mockLogger.calls.find(c => c.level === 'ERROR');
            assert.ok(errorLog);
            assert.ok(errorLog.context.taskId);
        });
    });
});

// ===== HELPER FUNCTIONS (dentro do arquivo de teste) =====
function createValidInput() {
    return {
        id: 'test-001',
        type: 'task',
        data: { message: 'Hello' }
    };
}

function createInvalidInput() {
    return null;
}
```

### Integration Test Template

```javascript
/**
 * Integration Test: [Feature Name]
 *
 * Tests: Integration between [Component A] and [Component B]
 * Setup: Requires [dependencies] running
 *
 * @group integration
 * @group [categoria]
 */

const { describe, it, before, after } = require('node:test');
const assert = require('node:assert');

// Components
const ComponentA = require('../../../src/path/to/component_a');
const ComponentB = require('../../../src/path/to/component_b');

// Real dependencies (nÃ£o mocks)
const { createNERV } = require('../../../src/nerv/nerv');
const logger = require('../../../src/core/logger');

describe('ComponentA + ComponentB Integration', () => {
    let nerv;
    let componentA;
    let componentB;

    before(async () => {
        // Setup: inicializar componentes REAIS
        nerv = await createNERV({ mode: 'local' });

        componentA = new ComponentA({ nerv, logger });
        componentB = new ComponentB({ nerv, logger });

        await componentA.initialize();
        await componentB.initialize();
    });

    after(async () => {
        // Cleanup: fechar conexÃµes
        await componentA.shutdown();
        await componentB.shutdown();
        await nerv.close();
    });

    describe('message flow A â†’ B', () => {
        it('should send message from A to B via NERV', async () => {
            const message = { type: 'TEST', data: 'hello' };

            // B escuta mensagens
            const received = new Promise(resolve => {
                componentB.on('message', resolve);
            });

            // A envia mensagem
            await componentA.sendMessage(message);

            // B recebe mensagem
            const receivedMessage = await received;
            assert.deepStrictEqual(receivedMessage, message);
        });

        it('should handle message timeout gracefully', async () => {
            // Simular B nÃ£o respondendo
            componentB.pause(); // mÃ©todo para pausar processamento

            const result = await componentA.sendMessageWithTimeout(
                { type: 'TEST' },
                { timeout: 1000 }
            );

            assert.strictEqual(result.status, 'timeout');
        });
    });

    describe('error propagation', () => {
        it('should propagate errors from B to A', async () => {
            componentB.simulateError(new Error('Test error'));

            await assert.rejects(
                () => componentA.sendMessage({ type: 'TEST' }),
                { message: /Test error/ }
            );
        });
    });
});
```

### E2E Test Template

```javascript
/**
 * E2E Test: [Flow Name]
 *
 * Tests: Complete user flow from [start] to [end]
 * Setup: Full system running
 *
 * @group e2e
 * @slow (pode levar > 10s)
 */

const { describe, it, before, after } = require('node:test');
const assert = require('node:assert');
const path = require('path');
const fs = require('fs');

// Helpers
const { startAgent, stopAgent, waitForAgent } = require('../../helpers/test_helpers');
const { writeTask, readResponse } = require('../../helpers/async_helpers');

describe('E2E: Full Task Flow', () => {
    let agentProcess;

    before(async () => {
        // Limpar ambiente
        cleanTestEnvironment();

        // Iniciar agente completo
        agentProcess = await startAgent({ mode: 'test' });

        // Aguardar ready
        await waitForAgent({ timeout: 10000 });
    });

    after(async () => {
        // Parar agente
        await stopAgent(agentProcess);

        // Limpar arquivos de teste
        cleanTestEnvironment();
    });

    it('should process task from creation to completion', async () => {
        // 1. Criar tarefa na fila
        const taskId = await writeTask({
            prompt: 'What is 2+2?',
            target: 'chatgpt',
            model: 'gpt-4'
        });

        // 2. Aguardar processamento (polling)
        const response = await waitForResponse(taskId, { timeout: 60000 });

        // 3. Validar resposta
        assert.ok(response);
        assert.strictEqual(response.status, 'DONE');
        assert.match(response.result, /4/);

        // 4. Verificar artefatos criados
        const responseFile = path.join(__dirname, '../../respostas', `${taskId}.txt`);
        assert.ok(fs.existsSync(responseFile));

        // 5. Verificar logs
        const logs = await readAgentLogs();
        assert.ok(logs.some(l => l.includes(`Task ${taskId} completed`)));
    });

    it('should handle multiple tasks concurrently', async () => {
        const tasks = [];

        // Criar 3 tarefas simultÃ¢neas
        for (let i = 0; i < 3; i++) {
            tasks.push(writeTask({ prompt: `Test ${i}` }));
        }

        const taskIds = await Promise.all(tasks);

        // Aguardar todas completarem
        const responses = await Promise.all(
            taskIds.map(id => waitForResponse(id, { timeout: 90000 }))
        );

        // Validar todas completaram
        assert.strictEqual(responses.length, 3);
        responses.forEach(r => {
            assert.strictEqual(r.status, 'DONE');
        });
    });
});

// ===== HELPERS LOCAIS =====
function cleanTestEnvironment() {
    // Limpar fila, logs, locks, etc
}

async function waitForResponse(taskId, { timeout = 30000 }) {
    const start = Date.now();
    const responseFile = path.join(__dirname, '../../respostas', `${taskId}.txt`);

    while (Date.now() - start < timeout) {
        if (fs.existsSync(responseFile)) {
            return JSON.parse(fs.readFileSync(responseFile, 'utf-8'));
        }
        await sleep(1000);
    }

    throw new Error(`Response timeout for task ${taskId}`);
}

async function readAgentLogs() {
    const logFile = path.join(__dirname, '../../logs', 'agente_current.log');
    return fs.readFileSync(logFile, 'utf-8').split('\n');
}

function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
}
```

---

## ğŸ”§ ConfiguraÃ§Ã£o de Ferramentas

### 1. Instalar DependÃªncias

```bash
# Coverage tool (c8 Ã© melhor que nyc para Node.js nativo)
npm install --save-dev c8

# Test runner (jÃ¡ estÃ¡ em Node.js 20+, mas adicionar tipos para IDE)
npm install --save-dev @types/node

# Mocking library (opcional, mas Ãºtil)
npm install --save-dev sinon

# API testing (para testes de servidor)
npm install --save-dev supertest

# Fake data (para fixtures)
npm install --save-dev @faker-js/faker
```

### 2. Configurar package.json

```json
{
    "scripts": {
        "test": "node --test tests/**/*.spec.js",
        "test:unit": "node --test tests/unit/**/*.spec.js",
        "test:integration": "node --test tests/integration/**/*.spec.js",
        "test:e2e": "node --test tests/e2e/**/*.spec.js",
        "test:regression": "node --test tests/regression/**/*.spec.js",

        "test:watch": "node --test --watch tests/**/*.spec.js",

        "test:coverage": "c8 --reporter=html --reporter=text npm test",
        "test:coverage:unit": "c8 --reporter=text npm run test:unit",

        "test:ci": "c8 --reporter=lcov --reporter=text npm test",

        "test:specific": "node --test",

        "test:debug": "node --inspect-brk --test tests/**/*.spec.js",

        "test:summary": "node scripts/test-summary.js"
    }
}
```

### 3. Configurar c8 (.c8rc.json)

```json
{
    "all": true,
    "include": ["src/**/*.js"],
    "exclude": [
        "src/**/*.test.js",
        "src/**/*.spec.js",
        "node_modules/**",
        "tests/**",
        "coverage/**"
    ],
    "reporter": ["html", "text", "lcov"],
    "check-coverage": true,
    "lines": 80,
    "functions": 75,
    "branches": 75,
    "statements": 80,
    "watermarks": {
        "lines": [80, 95],
        "functions": [75, 90],
        "branches": [75, 90],
        "statements": [80, 95]
    },
    "temp-directory": "./tests/tmp/.c8",
    "report-dir": "./coverage"
}
```

### 4. Criar setup.js (global test setup)

```javascript
/**
 * Global Test Setup
 * Executado UMA VEZ antes de todos os testes
 */

const fs = require('fs');
const path = require('path');

// Criar diretÃ³rios necessÃ¡rios
const dirs = [
    'tests/tmp',
    'tests/tmp/tasks',
    'tests/tmp/responses',
    'tests/tmp/logs',
    'coverage'
];

dirs.forEach(dir => {
    const fullPath = path.join(__dirname, '..', dir);
    if (!fs.existsSync(fullPath)) {
        fs.mkdirSync(fullPath, { recursive: true });
    }
});

// Configurar variÃ¡veis de ambiente para testes
process.env.NODE_ENV = 'test';
process.env.LOG_LEVEL = 'ERROR'; // Silenciar logs durante testes
process.env.BROWSER_MODE = 'launcher'; // Sempre launcher em testes

// Mock do logger global (opcional)
global.testLogger = {
    log: () => {}, // silent
    info: () => {},
    warn: () => {},
    error: () => {}
};

console.log('âœ… Global test setup complete');
```

### 5. Criar teardown.js (global test teardown)

```javascript
/**
 * Global Test Teardown
 * Executado UMA VEZ depois de todos os testes
 */

const fs = require('fs');
const path = require('path');

// Limpar arquivos temporÃ¡rios
const tmpDir = path.join(__dirname, '..', 'tests/tmp');
if (fs.existsSync(tmpDir)) {
    fs.rmSync(tmpDir, { recursive: true, force: true });
    console.log('âœ… Cleaned test tmp directory');
}

// Fechar conexÃµes pendentes (se houver)
// ...

console.log('âœ… Global test teardown complete');
```

---

## ğŸ“‹ Plano de MigraÃ§Ã£o

### FASE 1: PreparaÃ§Ã£o (Dia 1 - 4h)

**Objetivo**: Setup de ferramentas e estrutura

```bash
# 1. Instalar dependÃªncias
npm install --save-dev c8 sinon supertest @faker-js/faker @types/node

# 2. Criar estrutura de diretÃ³rios
mkdir -p tests/{unit/{core,nerv,kernel,driver,infra,server,state,logic},integration/{kernel,driver,api,queue,browser},e2e,regression,fixtures/{tasks,responses,config,dna},mocks,helpers,manual,performance}

# 3. Criar arquivos de configuraÃ§Ã£o
# - .c8rc.json
# - tests/setup.js
# - tests/teardown.js

# 4. Atualizar package.json com novos scripts

# 5. Mover testes existentes para nova estrutura
mv tests/test_config_validation.js tests/unit/core/test_config.spec.js
mv tests/test_health_endpoint.js tests/integration/api/test_health_endpoint.spec.js
# ... (14 arquivos)

# 6. Criar README.md em tests/
```

**Checklist**:
- [ ] DependÃªncias instaladas
- [ ] Estrutura de diretÃ³rios criada
- [ ] ConfiguraÃ§Ã£o c8 feita
- [ ] Setup/teardown globais criados
- [ ] package.json atualizado
- [ ] Testes existentes migrados
- [ ] README de testes criado

---

### FASE 2: ConsolidaÃ§Ã£o (Dia 2 - 4h)

**Objetivo**: Consolidar testes existentes na nova estrutura

```bash
# 1. Converter formato dos testes existentes
# - Adicionar imports do node:test
# - Usar describe/it ao invÃ©s de runTest()
# - Separar assertions claramente

# 2. Criar fixtures bÃ¡sicas
# - tasks/task_simple.json
# - responses/response_success.json
# - config/config_minimal.json

# 3. Criar mocks bÃ¡sicos
# - mock_logger.js
# - mock_nerv.js
# - mock_browser.js

# 4. Atualizar helpers.js
# - Renomear para test_helpers.js
# - Adicionar funÃ§Ãµes Ãºteis (waitFor, retry, cleanup)

# 5. Executar testes para validar migraÃ§Ã£o
npm test
```

**Checklist**:
- [ ] 14 testes convertidos para novo formato
- [ ] 10 fixtures bÃ¡sicas criadas
- [ ] 5 mocks bÃ¡sicos criados
- [ ] helpers.js consolidado
- [ ] Todos os testes passando

---

### FASE 3: ImplementaÃ§Ã£o CrÃ­tica âœ… COMPLETA (20/Jan/2026)

**Objetivo**: Implementar 15 suites de testes CRÃTICOS (ğŸ”´)

**Resultado Final**:

âœ… **Core (3 arquivos)**:
1. test_logger.spec.js (8 suites, 12+ tests) - ALL PASSING
2. test_schemas.spec.js (5 suites, 18 tests) - 6/18 PASSING (bugs encontrados)
3. test_config.spec.js (8 suites, 8+ tests) - modernizado

âœ… **NERV (2 arquivos)**:
4. test_nerv_core.spec.js (8 suites, 15 tests) - event bus
5. test_envelope.spec.js (8 suites, 20 tests) - protocol validation

âœ… **Kernel (3 arquivos)**:
6. test_execution_engine.spec.js (8 suites, 12 tests) - task lifecycle
7. test_task_runtime.spec.js (10 suites, 18 tests) - runtime context
8. test_policy_engine.spec.js (9 suites, 15 tests) - retry policies

âœ… **Driver (2 arquivos)**:
9. test_driver_factory.spec.js (8 suites, 12 tests) - driver creation
10. test_driver_adapters.spec.js (10 suites, 18 tests) - ChatGPT/Gemini

âœ… **Infra (4 arquivos)** - inclui 2 da FASE 2:
11. test_io.spec.js (10 suites, 20 tests) - ğŸ”´ INCLUI FIX P5.2
12. test_lock_manager.spec.js (10 suites, 14 tests) - PID validation
13. test_browser_pool.spec.js (migrado FASE 2)
14. test_puppeteer_launcher.spec.js (migrado FASE 2)

âœ… **Server (3 arquivos)**:
15. test_server_nerv_adapter.spec.js (10 suites, 12 tests) - NERV integration
16. test_api_router.spec.js (15 suites, 15 tests) - HTTP routes
17. test_middleware.spec.js (10 suites, 10 tests) - request processing

**Total Real**: 17 arquivos | ~154 testes | 100% dos crÃ­ticos cobertos

**PrÃ³ximo**: Executar todos os testes e corrigir bugs revelados

---

### FASE 4: ExpansÃ£o (Semanas 3-5 - ~120h)

**Objetivo**: Completar testes de ALTA e MÃ‰DIA prioridade

- **Semana 3**: Integration tests (API, Storage, NERV)
- **Semana 4**: State, Logic, Server components
- **Semana 5**: Cleanup, optimization, coverage > 80%

---

## ğŸ“Š MÃ©tricas de Sucesso

### KPIs de Testes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   METAS DE COBERTURA                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… Fase 1 (PreparaÃ§Ã£o):       14 testes migrados          â”‚
â”‚ âœ… Fase 2 (ConsolidaÃ§Ã£o):     20 testes rodando           â”‚
â”‚ âœ… Fase 3 (CrÃ­tica):          17 arquivos, ~154 testes    â”‚
â”‚    Status: COMPLETA 20/Jan/2026                           â”‚
â”‚    Cobertura: Core(3), NERV(2), Kernel(3), Driver(2),    â”‚
â”‚               Infra(4), Server(3)                         â”‚
â”‚ ğŸ¯ Fase 4 (ExpansÃ£o):         +200 testes (80% cov)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ† META FINAL:                                            â”‚
â”‚    â€¢ 350+ testes                                          â”‚
â”‚    â€¢ 80%+ line coverage                                   â”‚
â”‚    â€¢ 75%+ branch coverage                                 â”‚
â”‚    â€¢ < 15min tempo total                                  â”‚
â”‚    â€¢ 0% flaky tests                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Qualidade dos Testes

- **Velocidade**: Unit < 100ms, Integration < 1s, E2E < 10s
- **Estabilidade**: Taxa de falso positivo < 1%
- **Manutenibilidade**: 1 arquivo = 1 mÃ³dulo testado
- **Clareza**: Nomes descritivos, 1 assertion por test (quando possÃ­vel)
- **Coverage**: Testar happy path + error cases + edge cases

---

## ğŸš€ ComeÃ§ar Agora

### Quick Start (prÃ³xima 1 hora)

```bash
# 1. Instalar ferramentas
npm install --save-dev c8 sinon supertest @faker-js/faker

# 2. Criar estrutura bÃ¡sica
mkdir -p tests/unit/core tests/integration/api tests/e2e tests/fixtures tests/mocks

# 3. Criar primeiro teste convertido
# Converter test_config_validation.js para novo formato

# 4. Criar configuraÃ§Ã£o c8
# Adicionar .c8rc.json

# 5. Testar
npm run test:unit

# 6. Ver coverage
npm run test:coverage
```

---

**Status**: âœ… ESTRATÃ‰GIA COMPLETA DEFINIDA
**PrÃ³xima aÃ§Ã£o**: ComeÃ§ar FASE 1 (PreparaÃ§Ã£o)
**Tempo estimado**: 4 horas para setup inicial
**Resultado esperado**: Estrutura completa + 14 testes migrados
